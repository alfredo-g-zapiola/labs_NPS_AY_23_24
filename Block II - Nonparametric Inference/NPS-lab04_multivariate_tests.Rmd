---
title: "Lab 04 - Permutational Multivariate Tests"
date: 2022/10/14
author: "Nonparametric statistics ay 2021/2022"
output:
  
  html_document: 
    df_print: paged
  pdf_document: default
  html_notebook: 
    df_print: paged
  word_document: default
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(webgl = hook_webgl)
```

```{css, echo=FALSE}
.extracode {
background-color: lightblue;
}
```

*Disclaimer: The present material has been slightly adapted from the original R
script prepared by me for the a.y. 2020/2021
Nonparametric statistics course. I hereby assume responsibility for any error that may
be present in this document, I do apologise for them and invite you to let me know.*


```{r}

B = 100000
seed = 26111992
```


## Permutational Multivariate Tests
In this part of the lab, we will directly implement some permutational multivariate tests, applied to specific problems
Let's start with our first one...

## Two population multivariate test

We are given data of the week 12/09/2016 -> 18/09/2016 about the number of veichles that, each half-hour, enter Milan Low emission zone (the so called "areaC"). You want to know if the mean entrance pattern in the weekends is significantly different from the one in the weekdays.
Framed in a more rigorous way, being $\mathbf{Y}_{i,weekday} \overset{iid}{\sim} \mathbf{Y}_{weekday} \in \mathbb{R}^{48}$ and $\mathbf{Y}_{i,weekend} \overset{iid}{\sim} \mathbf{Y}_{weekend} \in \mathbb{R}^{48}$, we want to test the equality of the two distributions, namely, we want to devise a test of the type:
$$
H_0: \mathbf{Y}_{weekday} \overset{d}{=} \mathbf{Y}_{weekend}\;vs\;H_1:\mathbf{Y}_{weekday} \overset{d}{\neq} \mathbf{Y}_{weekend}
$$

Let's start by reading and rearranging the data.

```{r}
d1 = read.csv('areac_data/accessi-orari-areac-2016-09-12-00_00_00.csv', header=T)
d2 = read.csv('areac_data/accessi-orari-areac-2016-09-13-00_00_00.csv', header=T)
d3 = read.csv('areac_data/accessi-orari-areac-2016-09-14-00_00_00.csv', header=T)
d4 = read.csv('areac_data/accessi-orari-areac-2016-09-15-00_00_00.csv', header=T)
d5 = read.csv('areac_data/accessi-orari-areac-2016-09-16-00_00_00.csv', header=T)
d6 = read.csv('areac_data/accessi-orari-areac-2016-09-17-00_00_00.csv', header=T)
d7 = read.csv('areac_data/accessi-orari-areac-2016-09-18-00_00_00.csv', header=T)

week = rbind(d1[,2], d2[,2], d3[,2], d4[,2], d5[,2], d6[,2], d7[,2])
matplot(seq(0,47)/2,t(week), type='l', col=c(1,1,1,1,1,2,2), lty=1)

```

As you remember, we can actually choose whatever test statistic we may like: if the permutation scheme used during the test is likelihood-invariant, we will get in any case an exact test.
There are nevertheless better choices than others. Let's try to use the squared euclidean distance between the two sample mean vectors (admittedly a quite standard choice.)

```{r}
t1 = week[1:5,]
t2 = week[6:7,]

t1.mean = colMeans(t1)
t2.mean = colMeans(t2)

matplot(seq(0,47)/2,t(rbind(t1.mean,t2.mean)), type='l', col=c(1,2), lty=1)
```

Let's compute the test statistic

```{r}
n1 = dim(t1)[1]
n2 = dim(t2)[1]
n  = n1 + n2

T20 = as.numeric((t1.mean-t2.mean) %*% (t1.mean-t2.mean))
T20
```

To perform our test, we need to confront the test statistic against the (permutational) distribution of it under $H_0$.

```{r}
# Estimating the permutational distribution under H0

T2 = numeric(B)
set.seed(seed)
for(perm in 1:B){
  # Random permutation of indexes
  # When we apply permutations in a multivariate case, we keep the units together
  # i.e., we only permute the rows of the data matrix
  t_pooled = rbind(t1,t2)
  permutation = sample(n)
  t_perm = t_pooled[permutation,]
  t1_perm = t_perm[1:n1,]
  t2_perm = t_perm[(n1+1):n,]
  
  # Evaluation of the test statistic on permuted data
  t1.mean_perm = colMeans(t1_perm)
  t2.mean_perm = colMeans(t2_perm)
  T2[perm]  = (t1.mean_perm-t2.mean_perm) %*% (t1.mean_perm-t2.mean_perm) 
}
```

Let's now see the shape of the permutational distribution, compared with the computed test statistic (the green vertical line...)

```{r}
hist(T2,xlim=range(c(T2,T20)))
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)
```

The P-value will be amazingly low... but let's try to calculate it nevertheless

```{r}
p_val = sum(T2>=T20)/B
p_val
```

With this P-value, I can say, with a level of confidence higher than $95 \%$ that weekdays and weekends are significantly different

let's see another case now...

## Centre of symmetry of one multivariate population 

We're still in Milan, but now we want to check if the humidity of summer months is significantly different from the "non-comfort" threshold level $(65\%)$.
In other words, being $\mathbf{Y}_{i,humid} \overset{iid}{\sim} \mathbf{Y}_{hum} \in \mathbb{R}^{4}$, I want to test

$$
H_0: \mathbf{Y}_{humid} = \mathbf{\mu}_{0}\;vs\;H_1:\mathbf{Y}_{humid} \neq \mathbf{\mu}_0
$$
Let's read and plot the data also here

```{r}
hum = read.csv2('humidity_data/307_Umidita_relativa_2008_2014.csv', header=T)
hum = hum[,3]
hum = matrix(hum, ncol=12, byrow=T)[,6:9]

boxplot(hum)
matplot(t(hum), type='l', lty=1)

```

What is a reasonable permutation scheme to implement, and thus what is a reasonable test to perform? It is actually harder to do with respect to two-sample tests... but if we assume the distribution to be symmetric, reflections are permutationally invariant, and thus I can easily test this! Let's define the centre of symmetry

```{r}
mu0      = c(65, 65, 65, 65)
```

Let's compute the test statistic (here the squared distance between the sample mean and the hypothesised centre, but of course other choices are possible...)


```{r}
x.mean   = colMeans(hum)
n = dim(hum)[1]
p = dim(hum)[2]

T20 = as.numeric((x.mean-mu0) %*% (x.mean-mu0) )
```


And now, let's compute the permutational distribution!

```{r}
T2 = numeric(B) 
set.seed(seed)

for(perm in 1:B){
  # In this case we use changes of signs in place of permutations
  
  # Permuted dataset
  signs.perm = rbinom(n, 1, 0.5)*2 - 1
  hum_perm = mu0 + (hum - mu0) * matrix(signs.perm,nrow=n,ncol=p,byrow=FALSE)
  x.mean_perm = colMeans(hum_perm)
  T2[perm]  = (x.mean_perm-mu0)  %*% (x.mean_perm-mu0) 
}
```

let's plot the permutational distribution of the test statistic

```{r}
hist(T2,xlim=range(c(T2,T20)))
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)
```

and the p-value

```{r}
p_val <- sum(T2>=T20)/B
p_val

```

Also here, I can argue that the humidity during the summer months is, with a 95% level of confidence, significantly different from $65%$

Let's now see our last case...

## Two sample paired multivariate permutation test

In this case, we want to compare the temperature, humidity and wind-speed in 50 different days in Milan and Barcelona
Let's read the data
```{r}
t1 <- read.table('meteo_data/barcellona.txt', header=T)
t2 <- read.table('meteo_data/milano.txt', header=T)

```

Let's try to explore the data... we can work with the paired differences and plot them.

```{r}
library(rgl)
open3d()
plot3d(t1-t2, size=3, col='orange', aspect = F)
points3d(0,0,0, size=6)

p  <- dim(t1)[2]
n1 <- dim(t1)[1]
n2 <- dim(t2)[1]
n <- n1+n2

```

In terms of permutation schemes (and testing strategies...) to follow, the best choice is to compute the differences between the two groups, assume their distribution to be symmetric, and then perform a centre of symmetry test.

What is the best test statistics for the test? let's see...

```{r}
t1.mean <- colMeans(t1)
t2.mean <- colMeans(t2)
t1.cov  <-  cov(t1)
t2.cov  <-  cov(t2)
Sp      <- ((n1-1)*t1.cov + (n2-1)*t2.cov)/(n1+n2-2)
Spinv   <- solve(Sp)

delta.0 <- c(0,0,0)

diff <- t1-t2
diff.mean <- colMeans(diff)
diff.cov <- cov(diff)
diff.invcov <- solve(diff.cov)
```

Let's start with the squared euclidean distance between the difference in means and the hypothesised value

```{r}
T20 <- as.numeric((diff.mean-delta.0)  %*% (diff.mean-delta.0))
```

And then, let's perform the test

```{r}
T2 <- numeric(B)
set.seed(seed)
for(perm in 1:B)
  {
  # Random permutation
  # obs: exchanging data within couples means changing the sign of the difference
  signs.perm <- rbinom(n1, 1, 0.5)*2 - 1
  
  diff_perm <- diff * matrix(signs.perm,nrow=n1,ncol=p,byrow=FALSE)
  diff.mean_perm <- colMeans(diff_perm)
  diff.cov_perm <- cov(diff_perm)
  diff.invcov_perm <- solve(diff.cov_perm)
  
  T2[perm] <- as.numeric((diff.mean_perm-delta.0) %*% (diff.mean_perm-delta.0))
  }
```
Distribution and pvalue

```{r}
# plotting the permutational distribution under H0
hist(T2,xlim=range(c(T2,T20)),breaks=100)
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)


# p-value
p_val <- sum(T2>=T20)/B
p_val

```



Now, let's use the Mahalanobis distance, but "forgetting" about the covariance between the values

```{r}
T20 <- as.numeric( (diff.mean-delta.0) %*% solve(diag(diag(diff.cov))) %*% (diff.mean-delta.0))
# Estimating the permutational distribution under H0
T2 <- numeric(B)
set.seed(seed)
for(perm in 1:B)
  {
  # Random permutation
  # obs: exchanging data within couples means changing the sign of the difference
  signs.perm <- rbinom(n1, 1, 0.5)*2 - 1
  
  diff_perm <- diff * matrix(signs.perm,nrow=n1,ncol=p,byrow=FALSE)
  diff.mean_perm <- colMeans(diff_perm)
  diff.cov_perm <- cov(diff_perm)
  diff.invcov_perm <- solve(diff.cov_perm)
  

  T2[perm] <- as.numeric((diff.mean_perm-delta.0) %*% solve(diag(diag(diff.cov_perm))) %*% (diff.mean_perm-delta.0))
  
}

# plotting the permutational distribution under H0
hist(T2,xlim=range(c(T2,T20)),breaks=100)
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)


# p-value
p_val <- sum(T2>=T20)/B
p_val

```

and lastly, let's use the proper Mahalanobis distance

```{r}
T20 <- as.numeric((diff.mean-delta.0) %*% diff.invcov %*% (diff.mean-delta.0))



# Estimating the permutational distribution under H0

set.seed(seed)
T2 <- numeric(B)

for(perm in 1:B)
  {
  # Random permutation
  # obs: exchanging data within couples means changing the sign of the difference
  signs.perm <- rbinom(n1, 1, 0.5)*2 - 1
  
  diff_perm <- diff * matrix(signs.perm,nrow=n1,ncol=p,byrow=FALSE)
  diff.mean_perm <- colMeans(diff_perm)
  diff.cov_perm <- cov(diff_perm)
  diff.invcov_perm <- solve(diff.cov_perm)
  
  #T2[perm] <- as.numeric(n1 * (diff.mean_perm-delta.0) %*% (diff.mean_perm-delta.0))
  #T2[perm] <- as.numeric(n1 * (diff.mean_perm-delta.0) %*% solve(diag(diag(diff.cov_perm))) %*% (diff.mean_perm-delta.0))
  T2[perm] <- as.numeric(n1 * (diff.mean_perm-delta.0) %*% diff.invcov_perm %*% (diff.mean_perm-delta.0))
  }

# plotting the permutational distribution under H0
hist(T2,xlim=range(c(T2,T20)),breaks=100)
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)


# p-value
p_val <- sum(T2>=T20)/B
p_val

```




