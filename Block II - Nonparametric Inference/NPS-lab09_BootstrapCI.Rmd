---
title: "Lab 09 - Bootstrap Tests and p-values"
date: 2022/10/20
author: "Nonparametric statistics ay 2022/2023"
output:
  
  html_document: 
    df_print: paged
  pdf_document: default
  html_notebook: 
    df_print: paged
  word_document: default
editor_options: 
  chunk_output_type: inline
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(rgl)
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(webgl = hook_webgl)
```

```{css, echo=FALSE}
.extracode {
background-color: lightblue;
}
```

*Disclaimer: The present material has been slightly adapted from the original R
script prepared by me for the a.y. 2020/2021
Nonparametric statistics course. I hereby assume responsibility for any error that may
be present in this document, I do apologise for them and invite you to let me know.*

```{r}

seed=2781991
B=100000
library(pbapply)
library(parallel)
```

## Boostrap tests and Bootstrap P-Values
You have probably already realised how close (but yet quite different) permutational and bootstrap methods are. We have actually seen how to create confidence intervals out of a permutation test... Here we will create a test (and compute p-values!) out of a bootstrap confidence interval

Let's start by generating some data

```{r}
set.seed(seed)
x1=stabledist::rstable(1000,1.8,0)

# Plot data
hist(x1)
boxplot(x1, main = 'X1')
```

We want to perform a test on the median of this distribution, namely $H_0:median(X_1)=0\;vs\;H_1:median(X_1)\neq0$. Let's start by computing the sample median

```{r}
T.obs <- median(x1)
T.obs
```

Now, we need to compute the bootstrap distribution of the sample median. To do this I will show you an advanced (and parallel...) technique. Let's set up the cluster

```{r}
cl=makeCluster(parallel::detectCores()/2)
clusterExport(cl=cl,list('x1'))


```

And now, let's directly compute

```{r}
T.boot=pbreplicate(B,median(sample(x1, replace = T)),cl=cl)
```

Again, let's observe the distribution

```{r}
plot(ecdf(T.boot), main='Sample median')
abline(v = T.obs, lty=2)
```

And compute the bias, variance, and RMSE

```{r}
var=var(T.boot)
var
bias=mean(T.boot)-T.obs
bias
RMSE=sqrt(var+bias^2)
RMSE

```

We also know very well how to compute confidence intervals... so

```{r}

alpha <- 0.05

right.quantile <- quantile(T.boot, 1 - alpha/2)
left.quantile  <- quantile(T.boot, alpha/2)



CI.RP <- c(T.obs - (right.quantile - T.obs), T.obs - (left.quantile - T.obs))
names(CI.RP)=c('lwr','upr')

plot(ecdf(T.boot), main='Sample median')
abline(v = T.obs, lty=2)
abline(v = CI.RP)
```

How do I compute the p-value of such test? I know that the p-value is the lowest alpha level for which I reject $H_0$. This value can be found via a grid search (that is computationally intensive, I know... but we know how to write fast code in R, don't we?)

```{r}
alpha_grid=seq(0.001,0.5,by=0.001)
length(alpha_grid)
```

Let's compute the list of confidence intervals: I start by creating a function to be iterated...

```{r}
CI_calc=function(alpha_level){
  right.quantile <- quantile(T.boot, 1 - alpha_level/2)
  left.quantile  <- quantile(T.boot, alpha_level/2)
  out=c(T.obs - (right.quantile - T.obs), T.obs - (left.quantile - T.obs))
  names(out)=c('lwr','upr')
  return(out)
}
```


which I then iterate using lapply

```{r}
CI_list=pblapply(alpha_grid,CI_calc)
CI_mat=dplyr::bind_rows(CI_list)
```

And, I can now check if $0$ is contained in the CI... The values are sorted, so the first one that does not contain $0$ is the first one of the vector...

```{r}
check=CI_mat[,1]>0 | CI_mat[,2]<0
(alpha_grid[check])[1]
```

So, I do not (expectedly...) reject $H_0$

